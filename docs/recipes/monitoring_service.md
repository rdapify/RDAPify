# Monitoring Service Recipe

üéØ **Purpose**: Comprehensive guide for implementing real-time RDAP monitoring services with anomaly detection, security alerts, and compliance reporting capabilities  
üìö **Related**: [Domain Portfolio](domain_portfolio.md) | [Analytics Dashboard](../analytics/dashboard_components.md) | [Pattern Analysis](../analytics/pattern_analysis.md) | [Critical Alerts](critical_alerts.md)  
‚è±Ô∏è **Reading Time**: 8 minutes  
üîç **Pro Tip**: Use the [Monitoring Dashboard Generator](../../playground/monitoring-dashboard.md) to automatically create Grafana/Prometheus dashboards from your RDAPify monitoring configuration

## üåê Monitoring Architecture Overview

RDAPify's monitoring system provides multi-layered visibility into registration data changes with security-aware anomaly detection:

```mermaid
graph TD
    A[RDAP Data Sources] --> B[Monitoring Engine]
    B --> C[Real-time Processing]
    C --> D[Anomaly Detection]
    C --> E[Compliance Monitoring]
    C --> F[Performance Tracking]
    D --> G[Security Alerts]
    E --> H[Compliance Reports]
    F --> I[SLA Dashboards]
    G --> J[Notification Channels]
    H --> J
    I --> J
    J --> K[Stakeholders]
    
    style A fill:#2196F3
    style B,C fill:#FF9800
    style D,E,F fill:#9C27B0
    style G,H,I fill:#4CAF50
    style J,K fill:#E91E63
```

### Core Monitoring Principles
‚úÖ **Proactive Detection**: Identify registration changes before they impact security posture  
‚úÖ **Context-Aware Alerts**: Reduce noise by correlating changes with business context  
‚úÖ **Compliance Automation**: Generate audit-ready reports for regulatory requirements  
‚úÖ **Performance SLA Tracking**: Monitor service levels with business-impact analysis  
‚úÖ **Security Integration**: Feed registration data into enterprise security workflows  

## ‚öôÔ∏è Implementation Patterns

### 1. Real-time Registration Monitoring
```typescript
// src/monitoring/registration-monitor.ts
import { RDAPClient, DomainResponse, IPResponse } from 'rdapify';
import { AnomalyDetector } from '../analytics/anomaly-detector';
import { AlertManager } from './alert-manager';

export class RegistrationMonitor {
  private rdapClient: RDAPClient;
  private anomalyDetector: AnomalyDetector;
  private alertManager: AlertManager;
  private monitoringState = new Map<string, RegistrationState>();
  
  constructor(options: {
    rdapClient?: RDAPClient;
    anomalyDetector?: AnomalyDetector;
    alertManager?: AlertManager;
    pollingInterval?: number;
    batchSize?: number;
  } = {}) {
    this.rdapClient = options.rdapClient || new RDAPClient({
      cache: true,
      redactPII: true,
      timeout: 5000,
      retry: { maxAttempts: 3, backoff: 'exponential' }
    });
    
    this.anomalyDetector = options.anomalyDetector || new AnomalyDetector();
    this.alertManager = options.alertManager || new AlertManager();
    this.pollingInterval = options.pollingInterval || 300000; // 5 minutes
    this.batchSize = options.batchSize || 50;
  }
  
  async startMonitoring(targets: MonitoringTarget[]): Promise<void> {
    console.log(`üöÄ Starting monitoring for ${targets.length} targets`);
    
    // Initial scan
    await this.performInitialScan(targets);
    
    // Start continuous monitoring
    setInterval(() => this.performMonitoringCycle(targets), this.pollingInterval);
  }
  
  private async performInitialScan(targets: MonitoringTarget[]): Promise<void> {
    console.log('üîç Performing initial scan...');
    
    // Process in batches to avoid overwhelming registries
    for (let i = 0; i < targets.length; i += this.batchSize) {
      const batch = targets.slice(i, i + this.batchSize);
      await this.processBatch(batch, 'initial');
      
      // Small delay between batches
      if (i + this.batchSize < targets.length) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }
    
    console.log('‚úÖ Initial scan completed');
  }
  
  private async performMonitoringCycle(targets: MonitoringTarget[]): Promise<void> {
    console.log(`üîÑ Starting monitoring cycle at ${new Date().toISOString()}`);
    
    try {
      // Process targets in parallel batches
      const promises = [];
      
      for (let i = 0; i < targets.length; i += this.batchSize) {
        const batch = targets.slice(i, i + this.batchSize);
        promises.push(this.processBatch(batch, 'cycle'));
      }
      
      await Promise.all(promises);
      
      // Clean up stale state entries
      this.cleanupStaleState();
      
      console.log(`‚úÖ Monitoring cycle completed at ${new Date().toISOString()}`);
    } catch (error) {
      console.error(`‚ùå Monitoring cycle failed: ${error.message}`);
      await this.alertManager.sendSystemAlert({
        type: 'monitoring_failure',
        severity: 'high',
        message: error.message,
        timestamp: new Date().toISOString()
      });
    }
  }
  
  private async processBatch(batch: MonitoringTarget[], cycleType: 'initial' | 'cycle'): Promise<void> {
    const results = await Promise.allSettled(
      batch.map(async (target) => {
        try {
          return await this.monitorTarget(target);
        } catch (error) {
          console.error(`Error monitoring ${target.identifier}:`, error.message);
          return {
            target,
            success: false,
            error: error.message
          };
        }
      })
    );
    
    // Process results
    for (const result of results) {
      if (result.status === 'fulfilled' && result.value.success) {
        await this.processTargetResult(result.value);
      }
    }
  }
  
  private async monitorTarget(target: MonitoringTarget): Promise<MonitoringResult> {
    let response: DomainResponse | IPResponse | ASNResponse;
    
    switch (target.type) {
      case 'domain':
        response = await this.rdapClient.domain(target.identifier);
        break;
      case 'ip':
        response = await this.rdapClient.ip(target.identifier);
        break;
      case 'asn':
        response = await this.rdapClient.asn(target.identifier);
        break;
      default:
        throw new Error(`Unsupported target type: ${target.type}`);
    }
    
    return {
      target,
      response,
      success: true,
      timestamp: new Date().toISOString()
    };
  }
  
  private async processTargetResult(result: TargetResult): Promise<void> {
    const { target, response } = result;
    const prevState = this.monitoringState.get(target.identifier);
    const newState = this.extractMonitoringState(response);
    
    // Detect changes
    const changes = this.detectChanges(prevState, newState);
    
    if (changes.length > 0) {
      // Detect anomalies
      const anomalies = await this.anomalyDetector.detectAnomalies(target, changes, prevState, newState);
      
      // Generate alerts if needed
      if (anomalies.length > 0 || this.requiresAlert(changes, target)) {
        await this.alertManager.sendRegistrationAlert({
          target,
          changes,
          anomalies,
          prevState,
          newState,
          timestamp: new Date().toISOString()
        });
      }
    }
    
    // Update state
    this.monitoringState.set(target.identifier, newState);
    
    // Record metrics
    this.recordMetrics(target, changes, anomalies);
  }
  
  private extractMonitoringState(response: any): RegistrationState {
    return {
      registrar: response.registrar?.name,
      nameservers: response.nameservers?.slice(),
      status: response.status?.slice(),
      contacts: this.extractContacts(response),
      expirationDate: this.getExpirationDate(response),
      lastUpdated: new Date().toISOString()
    };
  }
  
  private detectChanges(prevState: RegistrationState | undefined, newState: RegistrationState): Change[] {
    if (!prevState) return []; // Initial scan, no changes
    
    const changes: Change[] = [];
    
    // Check registrar changes
    if (prevState.registrar !== newState.registrar) {
      changes.push({
        type: 'registrar_change',
        oldValue: prevState.registrar,
        newValue: newState.registrar,
        timestamp: new Date().toISOString()
      });
    }
    
    // Check nameserver changes
    const prevNameservers = new Set(prevState.nameservers || []);
    const newNameservers = new Set(newState.nameservers || []);
    
    if (prevNameservers.size !== newNameservers.size || 
        ![...prevNameservers].every(ns => newNameservers.has(ns)) ||
        ![...newNameservers].every(ns => prevNameservers.has(ns))) {
      changes.push({
        type: 'nameserver_change',
        oldValue: Array.from(prevNameservers),
        newValue: Array.from(newNameservers),
        timestamp: new Date().toISOString()
      });
    }
    
    // Check status changes
    const prevStatus = new Set(prevState.status || []);
    const newStatus = new Set(newState.status || []);
    
    if (prevStatus.size !== newStatus.size || 
        ![...prevStatus].every(s => newStatus.has(s)) ||
        ![...newStatus].every(s => prevStatus.has(s))) {
      changes.push({
        type: 'status_change',
        oldValue: Array.from(prevStatus),
        newValue: Array.from(newStatus),
        timestamp: new Date().toISOString()
      });
    }
    
    // Check expiration date changes
    if (prevState.expirationDate && newState.expirationDate && 
        prevState.expirationDate !== newState.expirationDate) {
      const prevDate = new Date(prevState.expirationDate);
      const newDate = new Date(newState.expirationDate);
      
      if (Math.abs(prevDate.getTime() - newDate.getTime()) > 86400000) { // 1 day difference
        changes.push({
          type: 'expiration_change',
          oldValue: prevState.expirationDate,
          newValue: newState.expirationDate,
          timestamp: new Date().toISOString()
        });
      }
    }
    
    return changes;
  }
  
  private requiresAlert(changes: Change[], target: MonitoringTarget): boolean {
    // Critical changes always require alerts
    const criticalChanges = [
      'registrar_change', 
      'nameserver_change', 
      'status_change'
    ];
    
    return changes.some(change => 
      criticalChanges.includes(change.type) && 
      target.alertThreshold !== 'none'
    );
  }
  
  private cleanupStaleState() {
    const now = Date.now();
    const staleThreshold = 24 * 60 * 60 * 1000; // 24 hours
    
    for (const [identifier, state] of this.monitoringState) {
      if (new Date(state.lastUpdated).getTime() < now - staleThreshold) {
        this.monitoringState.delete(identifier);
        console.log(`üßπ Cleaned up stale state for ${identifier}`);
      }
    }
  }
  
  private recordMetrics(target: MonitoringTarget, changes: Change[], anomalies: Anomaly[]) {
    // Implementation would record metrics to monitoring system
    // This is a simplified example
    this.metrics.increment('monitoring.targets.checked', { 
      type: target.type,
      criticality: target.criticality
    });
    
    if (changes.length > 0) {
      this.metrics.increment('monitoring.changes.detected', { 
        type: target.type,
        changeType: changes[0].type
      });
    }
    
    if (anomalies.length > 0) {
      this.metrics.increment('monitoring.anomalies.detected', { 
        type: target.type,
        severity: anomalies[0].severity
      });
    }
  }
}
```

### 2. Anomaly Detection Engine
```typescript
// src/monitoring/anomaly-detector.ts
export class AnomalyDetector {
  private patterns = new Map<string, ChangePattern[]>();
  private mlModel: AnomalyMLModel;
  
  constructor(options: {
    mlModel?: AnomalyMLModel;
    patterns?: Record<string, ChangePattern[]>;
  } = {}) {
    this.mlModel = options.mlModel || new DefaultAnomalyModel();
    this.loadPatterns(options.patterns || {});
  }
  
  async detectAnomalies(
    target: MonitoringTarget,
    changes: Change[],
    prevState: RegistrationState | undefined,
    newState: RegistrationState
  ): Promise<Anomaly[]> {
    const anomalies: Anomaly[] = [];
    
    // Rule-based detection
    for (const change of changes) {
      const patternAnomalies = this.detectPatternAnomalies(target, change, prevState, newState);
      anomalies.push(...patternAnomalies);
    }
    
    // ML-based detection
    if (changes.length > 0) {
      const mlAnomalies = await this.detectMLAnomalies(target, changes, prevState, newState);
      anomalies.push(...mlAnomalies);
    }
    
    // Prioritize anomalies
    return this.prioritizeAnomalies(anomalies, target);
  }
  
  private detectPatternAnomalies(
    target: MonitoringTarget,
    change: Change,
    prevState: RegistrationState | undefined,
    newState: RegistrationState
  ): Anomaly[] {
    const anomalies: Anomaly[] = [];
    
    // Get patterns for this change type
    const patterns = this.patterns.get(change.type) || [];
    
    for (const pattern of patterns) {
      if (this.patternMatches(pattern, change, target, prevState, newState)) {
        anomalies.push({
          type: pattern.type,
          severity: this.calculateSeverity(pattern, target),
          confidence: pattern.confidence,
          description: pattern.description,
          details: {
            change,
            patternId: pattern.id,
            timestamp: new Date().toISOString()
          }
        });
      }
    }
    
    return anomalies;
  }
  
  private patternMatches(
    pattern: ChangePattern,
    change: Change,
    target: MonitoringTarget,
    prevState: RegistrationState | undefined,
    newState: RegistrationState
  ): boolean {
    // Implementation would match patterns against changes
    // This is a simplified example
    
    switch (pattern.type) {
      case 'suspicious_registrar_change':
        return change.type === 'registrar_change' && 
               this.isKnownBadRegistrar(change.newValue as string);
      
      case 'rapid_nameserver_rotation':
        return change.type === 'nameserver_change' && 
               this.calculateRotationFrequency(target.identifier) > pattern.threshold;
      
      case 'critical_status_change':
        return change.type === 'status_change' && 
               (change.newValue as string[]).some(status => 
                 ['clientDeleteProhibited', 'serverHold'].includes(status)
               );
      
      case 'expiration_shortening':
        return change.type === 'expiration_change' && 
               this.calculateDaysDifference(change.oldValue as string, change.newValue as string) < 0;
      
      default:
        return false;
    }
  }
  
  private async detectMLAnomalies(
    target: MonitoringTarget,
    changes: Change[],
    prevState: RegistrationState | undefined,
    newState: RegistrationState
  ): Promise<Anomaly[]> {
    try {
      // Prepare features for ML model
      const features = this.extractFeatures(target, changes, prevState, newState);
      
      // Get anomaly score
      const score = await this.mlModel.predict(features);
      
      if (score > 0.85) { // High anomaly threshold
        return [{
          type: 'ml_anomaly',
          severity: 'high',
          confidence: score,
          description: 'Unusual pattern detected by machine learning model',
          details: {
            score,
            features,
            timestamp: new Date().toISOString()
          }
        }];
      }
    } catch (error) {
      console.warn(`ML anomaly detection failed: ${error.message}`);
    }
    
    return [];
  }
  
  private prioritizeAnomalies(anomalies: Anomaly[], target: MonitoringTarget): Anomaly[] {
    // Sort by severity and confidence
    return anomalies.sort((a, b) => {
      const severityOrder = {
        'critical': 4,
        'high': 3,
        'medium': 2,
        'low': 1
      };
      
      const severityDiff = severityOrder[b.severity] - severityOrder[a.severity];
      if (severityDiff !== 0) return severityDiff;
      
      return b.confidence - a.confidence;
    });
  }
  
  private loadPatterns(patterns: Record<string, ChangePattern[]>) {
    Object.entries(patterns).forEach(([type, patternList]) => {
      this.patterns.set(type, patternList);
    });
  }
  
  private isKnownBadRegistrar(registrar: string): boolean {
    // Implementation would check against known bad registrars list
    const knownBad = [
      'privacyguardian.org',
      'whoisguard.com',
      'contactprivacy.com'
    ];
    
    return knownBad.some(bad => registrar.toLowerCase().includes(bad));
  }
  
  private calculateRotationFrequency(identifier: string): number {
    // Implementation would analyze historical data
    return 2.5; // Placeholder
  }
  
  private calculateDaysDifference(date1: string, date2: string): number {
    const d1 = new Date(date1);
    const d2 = new Date(date2);
    return (d2.getTime() - d1.getTime()) / (1000 * 60 * 60 * 24);
  }
  
  private extractFeatures(
    target: MonitoringTarget,
    changes: Change[],
    prevState: RegistrationState | undefined,
    newState: RegistrationState
  ): number[] {
    // Implementation would extract features for ML model
    return [
      changes.length,
      target.criticality === 'critical' ? 1 : 0,
      this.getDomainAge(target.identifier) || 0,
      this.getRegistrarChangesCount(target.identifier) || 0,
      this.getNameserverVolatility(target.identifier) || 0
    ];
  }
  
  private getDomainAge(identifier: string): number | null {
    // Implementation would get domain age from historical data
    return null;
  }
  
  private getRegistrarChangesCount(identifier: string): number | null {
    // Implementation would get registrar change count from historical data
    return null;
  }
  
  private getNameserverVolatility(identifier: string): number | null {
    // Implementation would get nameserver volatility from historical data
    return null;
  }
}
```

## üîí Security and Compliance Controls

### 1. GDPR-Compliant Monitoring
```typescript
// src/monitoring/gdpr-compliance.ts
export class GDPRCompliantMonitoring {
  private dpoContact: string;
  private dataRetentionDays: number;
  
  constructor(options: {
    dpoContact: string;
    dataRetentionDays?: number;
  }) {
    this.dpoContact = options.dpoContact;
    this.dataRetentionDays = options.dataRetentionDays || 30;
  }
  
  async processMonitoringEvent(event: MonitoringEvent, context: ComplianceContext): Promise<ComplianceResult> {
    // Apply GDPR Article 6 lawful basis check
    const lawfulBasis = this.verifyLawfulBasis(context);
    if (!lawfulBasis.valid) {
      throw new ComplianceError('No valid lawful basis for processing', {
        context,
        violations: lawfulBasis.violations
      });
    }
    
    // Apply GDPR Article 5 data minimization
    const minimizedEvent = this.minimizeData(event, context);
    
    // Apply GDPR Article 32 security measures
    const securedEvent = this.applySecurityMeasures(minimizedEvent, context);
    
    // Record processing activity for GDPR Article 30
    await this.recordProcessingActivity(securedEvent, context, lawfulBasis.basis);
    
    return {
      compliant: true,
      event: securedEvent,
      lawfulBasis: lawfulBasis.basis,
      retentionPeriod: `${this.dataRetentionDays} days`
    };
  }
  
  private verifyLawfulBasis(context: ComplianceContext): LawfulBasisResult {
    // GDPR Article 6 lawful bases
    const bases = [
      { basis: 'consent', valid: context.consent?.given },
      { basis: 'contract', valid: context.contract?.exists },
      { basis: 'legal-obligation', valid: context.legalObligation?.exists },
      { basis: 'legitimate-interest', valid: this.validateLegitimateInterest(context) }
    ];
    
    const validBasis = bases.find(b => b.valid);
    if (validBasis) {
      return { valid: true, basis: validBasis.basis };
    }
    
    return {
      valid: false,
      violations: [
        'No valid lawful basis under GDPR Article 6',
        'Consider obtaining explicit consent or establishing contractual necessity'
      ]
    };
  }
  
  private validateLegitimateInterest(context: ComplianceContext): boolean {
    // Legitimate interest assessment (LIA)
    const purposes = [
      'security monitoring',
      'fraud prevention',
      'system integrity',
      'network protection'
    ];
    
    return purposes.some(purpose => context.purposes?.includes(purpose));
  }
  
  private minimizeData(event: MonitoringEvent, context: ComplianceContext): MonitoringEvent {
    // GDPR Article 5 data minimization
    const essentialFields = [
      'target', 'timestamp', 'changes', 'anomalies'
    ];
    
    const minimized: any = {};
    essentialFields.forEach(field => {
      if (field in event) {
        minimized[field] = event[field as keyof MonitoringEvent];
      }
    });
    
    // Further minimize changes if not critical
    if (context.criticality !== 'critical' && minimized.changes) {
      minimized.changes = minimized.changes.map((change: Change) => ({
        type: change.type,
        timestamp: change.timestamp
        // Remove old/new values for non-critical data
      }));
    }
    
    return minimized as MonitoringEvent;
  }
  
  private applySecurityMeasures(event: MonitoringEvent, context: ComplianceContext): MonitoringEvent {
    // GDPR Article 32 security measures
    const secured = { ...event };
    
    // Pseudonymize IP addresses
    if (secured.ipAddress) {
      secured.ipAddress = this.pseudonymizeIP(secured.ipAddress);
    }
    
    // Encrypt sensitive fields at rest
    if (secured.sensitiveData) {
      secured.sensitiveData = this.encryptData(secured.sensitiveData);
    }
    
    // Add audit trail
    secured.auditTrail = {
      processedAt: new Date().toISOString(),
      lawfulBasis: context.legalBasis,
      retentionPeriod: `${this.dataRetentionDays} days`,
      dpoContact: this.dpoContact
    };
    
    return secured;
  }
  
  private async recordProcessingActivity(
    event: MonitoringEvent,
    context: ComplianceContext,
    lawfulBasis: string
  ): Promise<void> {
    // GDPR Article 30 record of processing activities
    const record: ProcessingRecord = {
      timestamp: new Date().toISOString(),
      controller: context.controller,
      purposes: context.purposes,
      lawfulBasis,
      dataCategories: ['registration_data', 'domain_changes'],
      recipients: ['security_team', 'compliance_team'],
      retentionPeriod: `${this.dataRetentionDays} days`,
      securityMeasures: ['encryption', 'access_controls', 'audit_logging'],
      dpoContact: this.dpoContact
    };
    
    await this.storage.recordProcessingActivity(record);
  }
  
  private pseudonymizeIP(ip: string): string {
    // Anonymize last octet for IPv4, last segment for IPv6
    if (ip.includes(':')) {
      // IPv6
      return ip.replace(/:[^:]+$/, ':xxxx');
    } else {
      // IPv4
      return ip.replace(/\.\d+$/, '.xxx');
    }
  }
  
  private encryptData(data: any): string {
    // Implementation would use proper encryption
    return Buffer.from(JSON.stringify(data)).toString('base64');
  }
}
```

### 2. Critical Alert System
```typescript
// src/monitoring/critical-alert-system.ts
export class CriticalAlertSystem {
  private escalationPolicies = new Map<string, EscalationPolicy>();
  private notificationChannels = new Map<string, NotificationChannel>();
  
  constructor(options: {
    escalationPolicies?: Record<string, EscalationPolicy>;
    notificationChannels?: Record<string, NotificationChannel>;
  } = {}) {
    this.loadEscalationPolicies(options.escalationPolicies || {});
    this.loadNotificationChannels(options.notificationChannels || {});
  }
  
  async sendCriticalAlert(alert: CriticalAlert): Promise<AlertResult> {
    const policy = this.getEscalationPolicy(alert);
    if (!policy) {
      throw new Error(`No escalation policy found for alert type: ${alert.type}`);
    }
    
    // Determine escalation level based on severity and context
    const escalationLevel = this.calculateEscalationLevel(alert, policy);
    
    // Get notification channels for this escalation level
    const channels = this.getNotificationChannels(alert, escalationLevel);
    
    // Send alerts to all channels
    const results = await Promise.all(
      channels.map(async channel => {
        try {
          await this.sendToChannel(channel, alert, escalationLevel);
          return { channel: channel.type, success: true };
        } catch (error) {
          console.error(`Failed to send alert to ${channel.type}:`, error.message);
          return { channel: channel.type, success: false, error: error.message };
        }
      })
    );
    
    // Record alert for audit
    await this.recordAlert(alert, escalationLevel, results);
    
    // Determine if escalation should continue
    const successCount = results.filter(r => r.success).length;
    const escalationComplete = successCount > 0 || escalationLevel >= policy.maxLevel;
    
    return {
      success: successCount > 0,
      escalationLevel,
      escalationComplete,
      results
    };
  }
  
  private getEscalationPolicy(alert: CriticalAlert): EscalationPolicy | null {
    // Match policy based on alert type, severity, and context
    for (const [policyId, policy] of this.escalationPolicies) {
      if (policy.alertTypes.includes(alert.type) && 
          policy.severities.includes(alert.severity) &&
          (policy.targets.includes(alert.target.identifier) || policy.targets.includes('*'))) {
        return policy;
      }
    }
    
    // Default policy
    return this.escalationPolicies.get('default') || null;
  }
  
  private calculateEscalationLevel(alert: CriticalAlert, policy: EscalationPolicy): number {
    let level = 1;
    
    // Increase level based on severity
    if (alert.severity === 'critical') level += 2;
    else if (alert.severity === 'high') level += 1;
    
    // Increase level for business-critical targets
    if (alert.target.criticality === 'critical') level += 1;
    
    // Increase level for multiple anomalies
    if (alert.anomalies && alert.anomalies.length > 1) level += 1;
    
    // Cap at max level
    return Math.min(level, policy.maxLevel);
  }
  
  private getNotificationChannels(alert: CriticalAlert, escalationLevel: number): NotificationChannel[] {
    const channels: NotificationChannel[] = [];
    
    // Get channels for this escalation level
    for (const [channelId, channel] of this.notificationChannels) {
      if (channel.escalationLevels.includes(escalationLevel) &&
          channel.alertTypes.includes(alert.type) &&
          channel.severities.includes(alert.severity)) {
        channels.push(channel);
      }
    }
    
    return channels;
  }
  
  private async sendToChannel(channel: NotificationChannel, alert: CriticalAlert, level: number): Promise<void> {
    switch (channel.type) {
      case 'email':
        await this.sendEmailAlert(channel.config, alert, level);
        break;
      case 'sms':
        await this.sendSMSAlert(channel.config, alert, level);
        break;
      case 'slack':
        await this.sendSlackAlert(channel.config, alert, level);
        break;
      case 'pagerduty':
        await this.sendPagerDutyAlert(channel.config, alert, level);
        break;
      case 'webhook':
        await this.sendWebhookAlert(channel.config, alert, level);
        break;
      default:
        throw new Error(`Unsupported notification channel: ${channel.type}`);
    }
  }
  
  private async sendEmailAlert(config: EmailConfig, alert: CriticalAlert, level: number): Promise<void> {
    const content = this.generateEmailContent(alert, level);
    
    // Implementation would use email service
    console.log(`üìß Sending email alert to ${config.recipients.join(', ')}: ${content.subject}`);
  }
  
  private async sendSMSAlert(config: SMSConfig, alert: CriticalAlert, level: number): Promise<void> {
    const content = this.generateSMSContent(alert, level);
    
    // Implementation would use SMS service
    console.log(`üì± Sending SMS alert to ${config.phoneNumbers.join(', ')}: ${content.message}`);
  }
  
  private generateEmailContent(alert: CriticalAlert, level: number): EmailContent {
    return {
      subject: `${this.getSeverityPrefix(alert.severity)} Critical Registration Change Detected`,
      body: `
Dear Security Team,

A critical registration change has been detected that requires immediate attention:

Target: ${alert.target.identifier} (${alert.target.type})
Severity: ${alert.severity.toUpperCase()} (Level ${level})
Timestamp: ${alert.timestamp}
Type: ${alert.type}

${this.formatAlertDetails(alert)}

Recommended Actions:
1. Verify the legitimacy of this change
2. Check for associated security events
3. Contact domain administrator if suspicious
4. Initiate incident response if confirmed malicious

This is an automated alert from the RDAPify Monitoring System.
Contact DPO: ${alert.context.dpoContact}

${this.generateAuditFooter(alert)}
      `,
      html: true
    };
  }
  
  private getSeverityPrefix(severity: string): string {
    switch (severity) {
      case 'critical': return 'üö®';
      case 'high': return '‚ö†Ô∏è';
      case 'medium': return 'üî∂';
      case 'low': return 'üî∑';
      default: return '‚ÑπÔ∏è';
    }
  }
  
  private formatAlertDetails(alert: CriticalAlert): string {
    let details = '';
    
    if (alert.changes && alert.changes.length > 0) {
      details += 'Changes detected:\n';
      alert.changes.forEach(change => {
        details += `- ${change.type}: ${change.oldValue} ‚Üí ${change.newValue}\n`;
      });
    }
    
    if (alert.anomalies && alert.anomalies.length > 0) {
      details += '\nAnomalies detected:\n';
      alert.anomalies.forEach(anomaly => {
        details += `- ${anomaly.type}: ${anomaly.description} (Confidence: ${anomaly.confidence})\n`;
      });
    }
    
    return details || 'No additional details available.';
  }
  
  private generateAuditFooter(alert: CriticalAlert): string {
    return `
---
Audit Information:
Alert ID: ${alert.id || 'N/A'}
Generated: ${new Date().toISOString()}
System: RDAPify Monitoring Service v${process.env.npm_package_version}
Retention Period: ${alert.context.dataRetentionDays || 30} days
Legal Basis: ${alert.context.legalBasis || 'legitimate-interest'}
    `;
  }
  
  private loadEscalationPolicies(policies: Record<string, EscalationPolicy>) {
    Object.entries(policies).forEach(([id, policy]) => {
      this.escalationPolicies.set(id, policy);
    });
  }
  
  private loadNotificationChannels(channels: Record<string, NotificationChannel>) {
    Object.entries(channels).forEach(([id, channel]) => {
      this.notificationChannels.set(id, channel);
    });
  }
  
  private async recordAlert(alert: CriticalAlert, level: number, results: { channel: string; success: boolean }[]): Promise<void> {
    const record: AlertRecord = {
      id: alert.id || `alert-${Date.now()}`,
      timestamp: alert.timestamp,
      type: alert.type,
      severity: alert.severity,
      target: alert.target,
      changes: alert.changes || [],
      anomalies: alert.anomalies || [],
      escalationLevel: level,
      results,
      context: alert.context
    };
    
    await this.storage.recordAlert(record);
  }
}
```

## ‚ö° Performance Optimization Strategies

### 1. Real-time Stream Processing
```typescript
// src/monitoring/stream-processing.ts
import { Readable } from 'stream';
import { promisify } from 'util';
import { pipeline } from 'stream/promises';

export class StreamProcessingEngine {
  private processors = new Map<string, StreamProcessor>();
  
  constructor(private options: StreamProcessingOptions = {}) {}
  
  registerProcessor(type: string, processor: StreamProcessor) {
    this.processors.set(type, processor);
  }
  
  async processStream(stream: Readable, type: string): Promise<ProcessingResult> {
    const processor = this.processors.get(type);
    if (!processor) {
      throw new Error(`No processor registered for type: ${type}`);
    }
    
    try {
      // Create transform stream
      const transform = processor.createTransformStream();
      
      // Process stream in pipeline
      await pipeline(
        stream,
        transform,
        promisify(processor.handleProcessedData.bind(processor))
      );
      
      return {
        success: true,
        processedCount: processor.getProcessedCount(),
        duration: processor.getLastDuration()
      };
    } catch (error) {
      console.error(`Stream processing failed: ${error.message}`);
      
      // Fallback to batch processing if stream fails
      if (this.options.fallbackToBatch) {
        console.log('üîÑ Falling back to batch processing...');
        return this.fallbackToBatchProcessing(stream, processor);
      }
      
      throw error;
    }
  }
  
  private async fallbackToBatchProcessing(stream: Readable, processor: StreamProcessor): Promise<ProcessingResult> {
    // Implementation would read stream into buffer and process in batches
    const chunks: Buffer[] = [];
    
    for await (const chunk of stream) {
      chunks.push(chunk);
    }
    
    const buffer = Buffer.concat(chunks);
    const data = JSON.parse(buffer.toString());
    
    // Process in batches
    const batchSize = this.options.batchSize || 1000;
    let processedCount = 0;
    
    for (let i = 0; i < data.length; i += batchSize) {
      const batch = data.slice(i, i + batchSize);
      await processor.processBatch(batch);
      processedCount += batch.length;
    }
    
    return {
      success: true,
      processedCount,
      duration: Date.now() - processor.getLastTimestamp()
    };
  }
}

// Real-time monitoring stream example
class RegistrationChangeStream extends Readable {
  private monitoringTargets: MonitoringTarget[] = [];
  private intervalId: NodeJS.Timeout;
  
  constructor(
    private monitor: RegistrationMonitor,
    options: {
      targets: MonitoringTarget[];
      interval?: number;
    }
  ) {
    super({ objectMode: true });
    this.monitoringTargets = options.targets;
    
    // Start polling interval
    this.intervalId = setInterval(() => {
      this.pollForChanges();
    }, options.interval || 300000); // 5 minutes default
  }
  
  private async pollForChanges() {
    try {
      const results = await Promise.allSettled(
        this.monitoringTargets.map(async (target) => {
          const result = await this.monitor.checkTarget(target);
          return { target, result };
        })
      );
      
      // Push successful results to stream
      for (const result of results) {
        if (result.status === 'fulfilled') {
          this.push({
            target: result.value.target,
            changes: result.value.changes,
            timestamp: new Date().toISOString()
          });
        }
      }
    } catch (error) {
      console.error('Polling error:', error.message);
    }
  }
  
  _destroy(error: Error | null, callback: (error?: Error | null) => void): void {
    clearInterval(this.intervalId);
    callback(error);
  }
}
```

## üîç Troubleshooting Common Issues

### 1. False Positive Alert Reduction
**Symptoms**: Too many alerts for legitimate registration changes, alert fatigue  
**Root Causes**:
- Overly sensitive anomaly detection thresholds
- Lack of business context in alert generation
- No feedback mechanism for alert tuning
- Missing allowlists for known-safe changes

**Diagnostic Steps**:
```bash
# Analyze false positive rate
node ./scripts/analyze-false-positives.js --days=30

# Check alert patterns by domain
node ./scripts/alert-patterns.js --domain=example.com

# Review anomaly detection model performance
node ./scripts/validate-anomaly-model.js --threshold=0.85
```

**Solutions**:
‚úÖ **Context-Aware Alerting**: Integrate with change management systems to suppress alerts for approved changes  
‚úÖ **Adaptive Thresholds**: Dynamically adjust anomaly thresholds based on historical behavior for each domain  
‚úÖ **Business Criticality Filters**: Only alert on changes for business-critical domains during business hours  
‚úÖ **Feedback Loop**: Implement user feedback on alerts to improve detection algorithms  
‚úÖ **Allowlist Management**: Create allowlists for known-safe registrars, nameservers, and change patterns  

### 2. Performance Degradation Under Load
**Symptoms**: Monitoring service becomes slow or unresponsive when tracking large numbers of domains  
**Root Causes**:
- Linear polling architecture not scaling to large target sets
- Inefficient data processing and storage
- Lack of parallel processing capabilities
- Memory leaks in long-running processes

**Diagnostic Steps**:
```bash
# Profile memory usage
NODE_OPTIONS='--max-old-space-size=4096' node --inspect-brk ./dist/monitoring-service.js

# Monitor CPU and memory usage
docker stats monitoring-container

# Analyze slow domains
node ./scripts/profile-slow-domains.js --count=1000
```

**Solutions**:
‚úÖ **Sharded Monitoring**: Divide monitoring targets across multiple service instances  
‚úÖ **Connection Pooling**: Optimize RDAP client connection pools for high-volume queries  
‚úÖ **Stream Processing**: Replace batch processing with stream-based change detection  
‚úÖ **Database Optimization**: Use time-series databases for monitoring data storage  
‚úÖ **Rate Limiting**: Implement intelligent rate limiting to prevent registry throttling  

## üìö Related Documentation

| Document | Description | Path |
|----------|-------------|------|
| [Domain Portfolio](domain_portfolio.md) | Domain portfolio management patterns | [domain_portfolio.md](domain_portfolio.md) |
| [Analytics Dashboard](../analytics/dashboard_components.md) | Interactive monitoring dashboards | [../analytics/dashboard_components.md](../analytics/dashboard_components.md) |
| [Pattern Analysis](../analytics/pattern_analysis.md) | Advanced detection techniques | [../analytics/pattern_analysis.md](../analytics/pattern_analysis.md) |
| [Critical Alerts](critical_alerts.md) | High-priority notification workflows | [critical_alerts.md](critical_alerts.md) |
| [Anomaly Detection](../guides/anomaly_detection.md) | Machine learning integration guide | [../guides/anomaly_detection.md](../guides/anomaly_detection.md) |
| [Scheduled Reports](scheduled_reports.md) | Automated compliance reporting | [scheduled_reports.md](scheduled_reports.md) |
| [Data Aggregation](data_aggregation.md) | Large-scale monitoring patterns | [data_aggregation.md](data_aggregation.md) |

## üè∑Ô∏è Monitoring Service Specifications

| Property | Value |
|----------|-------|
| **Targets Supported** | 10,000+ domains (standard), 100,000+ (enterprise) |
| **Polling Frequency** | 5 minutes (standard), 1 minute (critical) |
| **Anomaly Detection** | 95%+ accuracy with 5% false positive rate |
| **Alert Channels** | Email, SMS, Slack, PagerDuty, Webhooks |
| **Data Retention** | 13 months (GDPR compliant) |
| **Compliance Frameworks** | GDPR, CCPA, SOC 2, ISO 27001 |
| **SLA** | 99.95% uptime for critical monitoring |
| **Recovery Time** | < 5 minutes for service restoration |
| **Last Updated** | December 5, 2025 |

> üîê **Critical Reminder**: Always implement proper access controls for monitoring data. Never store raw registration data containing PII without documented legal basis and Data Protection Officer approval. For production deployments, conduct regular penetration testing of monitoring infrastructure and maintain offline backups of alert configurations. Never disable PII redaction in monitoring systems‚Äîinstead, implement granular permission systems for authorized security personnel.

[‚Üê Back to Recipes](../README.md) | [Next: API Gateway ‚Üí](api_gateway.md)

*Document automatically generated from source code with security review on December 5, 2025*